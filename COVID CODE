import pandas as pd
import os,os.path
import numpy as np

datapath1='C:\\Users\\Admin\\Downloads\\PROJECT\\covid-chestxray-dataset-master'
dataset_path='C:\\Users\\Admin\\Downloads\\PROJECT\\dataset'

categories=os.listdir(dataset_path)
print(categories)

dataset=pd.read_csv(os.path.join(datapath1,'C:\\Users\\Admin\\Downloads\\PROJECT\\covid-chestxray-dataset-master\\metadata.csv'))
findings=dataset['finding']
image_names=dataset['filename']
positives_index=np.concatenate((np.where(findings=='Pneumonia/Viral/COVID-19')[0],np.where(findings=='Pneumonia/Viral/SARS')[0]))
positive_image_names=image_names[positives_index]
import cv2

for positive_image_name in positive_image_names:
    image=cv2.imread(os.path.join(datapath1,'C:\\Users\\Admin\\Downloads\\PROJECT\\covid-chestxray-dataset-master\\images',positive_image_name))
    try:
        cv2.imwrite(os.path.join('C:\\Users\\Admin\\Downloads\\PROJECT\\dataset\\Covid19 Positive',positive_image_name),image)
    except Exception as e:
        print(e)
        datapath2='C:\\Users\\Admin\\Downloads\\PROJECT\\Coronahack-Chest-XRay-Dataset'

dataset=pd.read_csv(os.path.join(datapath2,'C:\\Users\\Admin\\Downloads\\PROJECT\\Coronahack-Chest-XRay-Dataset\\Chest_xray_Corona_Metadata.csv'))
findings=dataset['Label']
image_names=dataset['X_ray_image_name']
negative_index=np.where(findings=='Normal')[0]
negative_image_names=image_names[negative_index]
import cv2
for negative_image_name in negative_image_names:
    image=cv2.imread(os.path.join(datapath2,'C:\\Users\\Admin\\Downloads\\PROJECT\\Coronahack-Chest-XRay-Dataset\\images',negative_image_name))
    try:
        cv2.imwrite(os.path.join('C:\\Users\\Admin\\Downloads\\PROJECT\\dataset\\Covid19 Negative',negative_image_name),image)
    except Exception as e:
        print(e)
 negative_image_names.shape
 import cv2,os

data_path='C:\\Users\\Admin\\Downloads\\PROJECT\\dataset'
categories=os.listdir(data_path)
labels=[i for i in range(len(categories))]

label_dict=dict(zip(categories,labels)) #empty dictionary

print(label_dict)
print(categories)
print(labels)
img_size=100
data=[]
target=[]


for category in categories:
    folder_path=os.path.join(data_path,category)
    img_names=os.listdir(folder_path)
        
    for img_name in img_names:
        img_path=os.path.join(folder_path,img_name)
        img=cv2.imread(img_path)

        try:
            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           
            #Coverting the image into gray scale
            resized=cv2.resize(gray,(img_size,img_size))
            #resizing the gray scale into 100x100, since we need a fixed common size for all the images in the dataset
            data.append(resized)
            target.append(label_dict[category])
            #appending the image and the label(categorized) into the list (dataset)

        except Exception as e:
            print('Exception:',e)
            #if any exception rasied, the exception will be printed here. And pass to the next image
import numpy as np

data=np.array(data)/255.0
data=np.reshape(data,(data.shape[0],img_size,img_size,1))
target=np.array(target)

from keras.utils import np_utils

new_target=np_utils.to_categorical(target)
np.save('data',data)
np.save('target',new_target)
import numpy as np

data=np.load('data.npy')
target=np.load('target.npy')
from keras.models import Sequential
from keras.layers import Dense,Activation,Flatten
from keras.layers import Conv2D,MaxPooling2D,Dropout

model=Sequential()

model.add(Conv2D(64,(3,3),input_shape=(100,100,1)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
#The first CNN layer followed by Relu and MaxPooling layers

model.add(Conv2D(32,(3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
#The second convolution layer followed by Relu and MaxPooling layers

model.add(Flatten())
#Flatten layer to stack the output convolutions from second convolution layer
model.add(Dropout(0.5))
model.add(Dense(1000,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(128,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64,activation='relu'))
#Dense layer of 64 neurons
model.add(Dense(2,activation='softmax'))
#The Final layer with two outputs for two categories

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
from sklearn.model_selection import train_test_split

train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)
from tensorflow.keras.callbacks import ModelCheckpoint
checkpoint = ModelCheckpoint('model-{epoch:03d}.h5',monitor='val_loss',verbose=0,save_best_only=True,mode='auto',save_weights_only=True)
history=model.fit(train_data,train_target,epochs=20,callbacks=[checkpoint],validation_split=0.1)
from matplotlib import pyplot as plt

plt.plot(history.history['loss'],'r',label='training loss')
plt.plot(history.history['val_loss'],label='validation loss')
plt.xlabel('# epochs')
plt.ylabel('loss')
plt.legend()
plt.show()
plt.plot(history.history['accuracy'],'r',label='training accuracy')
plt.plot(history.history['val_accuracy'],label='validation accuracy')
plt.xlabel('# epochs')
plt.ylabel('loss')
plt.legend()
plt.show()
print(model.evaluate(test_data,test_target))
